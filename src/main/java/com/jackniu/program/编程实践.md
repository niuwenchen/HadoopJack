## 编程实践

    Hadoop程序开发的独门绝技
    在本地，伪随机和全分布模式下调试程序
    程序数据的完整性检查和回归调试
    日志和监控
    性能调优
  
Hadoop编程与传统编程不同的主要体现在两个方面，其一，Hadoop程序主要是关于数据处理的，其二，Hadoop程序运行在一组
分布的计算机上。这两点差异使开发和调试过程发生改变。

### 6.1 开发MapReduce程序
Hadoop三种模式，本地，为分布与全分布，大致对应于开发，筹划和运营3种部署方案。可能需要有运行在不同工作负载的多个集群。例如，在内部集群上
可以运行许多中小规模的作业，在云上的集群可以更高效的运行庞大但不频繁发生的作业。

    bin/hadoop fs  -conf conf.cluster/hadoop-site.xml  -lsr
    全分布模式下集群的所有文件
    
    cut datafile| RandomSample.py 10
    假设已经安装了各种不同的配置，并且知道为每个hadoop配置提供数据
    
### 6.1.1 本地模式
本地模式使用的数据是本地文件系统中的文件。 wc -l 查看多少条数据，本地模式最多只允许有一个reducer

1 完整性检查
大多数MapReduce程序的数学错误并不会引发威胁性的错误消息，故不引人注意。在技术上是正确的并且运行顺利，但在数学上可能是错误的。最终
的结果也没有用。

2 回归测试
对于回归测试，保存map阶段的输出会很有帮助，有助于隔离出bug是在map阶段还是在reduce阶段，可以运行不带reduce的MapReduce作业
来保存map阶段的输出。 -D mapred.reduce.tasks=0.仅有mapper的作业中，会生成多个文件，每个map任务都会将它的
输出写入自己的文件中。全部拷贝到一起。

.part-00000.cr,是一个为文件part-00000保存校验和的内部文件。

一般而言，reduce中每个键对应的一组值被联结在一起，它们的顺序是由Hadoop决定的。但是Hadoop并不保证这些值按照一定的顺序排列。

在开发中使用采样哦户的数据集，因为他相对于生产环境中所使用的数据，在结构和属性上更具代表性。但是你可以构造亮一个考虑边界值
的输入数据集，这种数据集在生产数据中并不典型。可以插入空值，额外的制表符和其他不寻常的记录。

3 使用Long而不是Int
大多数程序员本能的使用int类型来表示整数值。在java中int类型可以容纳2^31 -1 至 -2^31之间的任何整数，大多数程序是足够的，
可是在处理hadoop这中规模的数据时，一些计数器的变量会需要更大的范围，并不罕见。在开发数据集的环境下是不会有这种
需求的，设计规模小。 将数值变为long还是LongWritable以应对未来的规模扩展

### 6.1.2 伪分布式模式
在自己的计算机上启动所有的守护进程，让它们就像工作在集群上一样。和这个计算机的交互就像和一个Hadoop集群交互一样，将数据放入
自己的HDFS文件系统中。

1 日志
logs目录下会有任务运行的文件，不同的服务(NameNode,DataNode)会有不同的日志文件，可以自己定义日志输出信息到STDOUT和STDERR
Hadoop分别将它们记录在文件stdout和stderr中，/logs/userlogs

除了将日志输出到STDOUT和STDERR，还可以使用SetStatus()方法传送实时的状态信息，该方法在Reporter对象总。
配置history 还是非常有用的

    2.x中使用MapReduce JobHistory Server，http://jhs_host:port/，端口号默认为19888，地址由参数mapreduce.jobhistory.webapp.address配置管理，使用命令mapred historyserver启动 

### 6.2 生产集群上的监视和调试
### 6.2.1 计数器
可以在Hadoop作业中插桩计数器来分析其整体运行。在程序中定义不同的计数器，分别累计特定事件的发生次数。对于来自同一个作业中的所有任务
的相同计数器，Hadoop会自动对他们进行求和，以反映整个作业的情况。这些计数器的数值会在JobTracker的Web用户界面中与Hadoop
的内部计数器一起显示。

计数器的典型应用是用来跟踪不同的输入记录类型，特别是跟踪“坏”记录。如果有些数据缺失的话可以用来跟踪
统计缺失数量，做一些数据的实时检查。

Reporter.incrCounter()方法增加计数器

    reporter.incrCounter(ClaimsCounters.QUOTED,1);
    在Web界面总显示:
    AverageWithCombiner$MapClass$ClaimsCounters: QUOTED 1
    
    Streaming过程也可以使用计数器，需要像STDERR发送一个特别格式的字符串:
        reporter:counter:group,counter,amount
     这里的group,counter,amount都以相应参数形式发送到Java的incrCounter中
     Python 中:sys.stderr.write("reporter:counter:ClaimsCounters,MISSING,1\n") \n是必须的
     
### 6.2.2 跳过坏记录
程序处理新的数据，新的数据可能引发新的异常，

Hadoop对硬件失效所采取的恢复机制无法应对由于坏记录所导致的确定性软件失效，相反，提供了一个特征，用来跳过哪些被却醒会
导致任务崩溃的记录。如果这个特征被启动，任务在重试几次后就会进行skipping模式。只要在skipping模式中，TaskTracker就会跟踪
并确定哪个记录区域会导致失效。于是TaskTracker会重启这个任务，并忽略这个坏记录区域。

1. 在Java中配置记录跳读
    Java中，这个特征由类SkipBadRecords来控制
    
        public static void setMapperMaxSkipRecords(Configuration conf,long maxSkipRecs);
        public static void setReducerMaxSkipGroups(Configuration conf,long maxSkipRecs);
     Hadoop寻找跳读区域，每次取跳读区域中一半的任务执行，并判断这一半有没有坏记录。这个过程不断迭代，
     直到跳读区域的大小在可接受的范围内。
     
        Hadoop常规的任务恢复机制: JobConf.setMaxMapAttempts() 
     
     触发skipping: void setAttemptStartSkipping(Configuration conf,int attemptToStartSkipping)
     Hadoop会把跳过的记录写入HDFS供以后分析，以 序列文件的形式_log/skip 目录
        
        hadoop  fs  -text  <序列文件>
     
### 6.2.3 用IsolationRunner重新运行出错的任务

         
     

